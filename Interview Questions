Interview Questions:

HIVE:
Q: Can we do DDL operations in HIVE table.
	In Hive Update and Delete work based on some limitations

    1.It can only be performed on tables that support ACID.
    2.If a table is to be used in ACID writes (insert, update, delete) then the table property “transactional” must be set on                  that table.
    3.Only ORC file format is supported in this.
    4.Tables must be bucketed to make use of these features.
	
NOTE: HIVE creates Delta files for each Update, Insert and Delete operations. Old data is still available in HDFS until COMPACTION is performed in HIVE

Q: How do you create a dynamic table in HIVE without give create table column specification
A:
	Download the data from DB to HDFS using Sqoop in AVRO format
	Extract schema from .avro data in HDFS using hadoop jar avro-tools-1.8.1.jar getschema /user/hduser/custavro/part-m-00000.avro > /home/hduser/customer.avsc
	Then create Hive table using the schema
		create external table customeravro 
		stored as AVRO 
		location '/user/hduser/custavro' 
		TBLPROPERTIES('avro.schema.url'='hdfs:///tmp/customer.avsc');